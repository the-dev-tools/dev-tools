# Repository Guidelines

## Purpose & Audience
This guide is written exclusively for embedded AI agents operating inside the DevTools repository. Your job is to execute the precise task requested, integrate gracefully with human authors, and leave the workspace cleaner than you found it. Always read the latest user context plus `CLAUDE.md` before acting—the latter captures architecture, domain vocabulary (flow nodes, delta system, Effect-TS patterns), and recent feature work such as request node duplication. When the user asks for clarification, respond candidly about what you checked or why you could not comply; do not improvise requirements that were not provided in the prompt or our governance documents. Favor explicit confirmations over assumptions, and make the reasoning chain observable through short comments in the chat when the path forward is ambiguous.

## Project Structure & Key Packages
The monorepo is managed by Nx and pnpm. User applications live under `apps/`: the Electron desktop shell (`desktop`), the Go CLI (`cli`), the browser recorder extension (`api-recorder-extension`), and the marketing site (`web`). Shared services, libraries, and generated code live under `packages/`. Of special importance: `packages/server` (Go backend, Connect RPC endpoints), `packages/db` (shared SQL drivers, sqlc-generated queries), `packages/spec` (TypeSpec definitions that emit protobuf and Connect bindings), `packages/ui` (component library), `packages/client` (React front-end) and `packages/worker-js` (flow execution workers). Tooling and common configuration reside in `configs/`, `tools/`, and `docs/`; study `docs/CONTRIBUTING.md` if you need additional context on workflow expectations. Generated build artifacts must land in `dist/` and never stay checked in. Go fixtures and integration helpers belong in `packages/server/test`. When tracing code paths, remember that RPC implementations live in `packages/server/internal/api`, domain services live in `packages/server/internal/service`, and database access is largely mediated through sqlc output under `packages/server/pkg/gen`.

## Toolchain & Environment Workflow
Always enter the reproducible environment with `nix develop`. If you are forced to run a command from outside the shell, prefix it with `nix develop -c` so that the correct Go toolchain, pnpm version, and SQLite drivers are available. Prefer orchestrated commands over raw executables: `task dev:desktop` starts the Electron app; `pnpm nx run client:dev` boots the Vite-powered UI; `pnpm nx run server:dev` launches the Go API with hot reload; `pnpm nx run spec:build` regenerates RPC contracts. Repository-wide quality checks run through `task lint`, `task test`, and `task test:ci`. `task fix` chains Prettier and syncpack; it is safe to run only when the user wants automated formatting. For cross-project sweeps, use `pnpm nx run-many --targets=lint,typecheck --nxBail` to surface failures fast. Tests and builds default to local resources; do not introduce commands that reach out to the network without an explicit request.

## AI Agent Operating Procedure
Before editing files, summarize your intent, craft a plan when the task spans multiple logical actions, and get confirmation if the user’s request is underspecified. Reference files using `path:line` format (e.g., `packages/server/internal/api/rcollection/handler.go:42`). Use `rg` for search and `pnpm exec` wrappers when invoking local CLIs. Never revert changes you did not author. When generating content, prefer ASCII and use end-of-line comments sparingly. After each batch of edits, run `git status -sb` to ensure you have only touched the expected files, and review the diff with `git diff` (or `git diff --stat`). If tests are relevant and cheap, run them; if they are costly or out of scope, explain why you skipped them. The final response must include what changed, how to validate it, and optional next steps. Do not commit unless the user explicitly instructs you to do so. Respect the current sandbox guarantees even though this harness grants full filesystem access.

## Go Implementation Principles
The Go backend favors idiomatic, function-oriented design: lean packages, exported constructors only when the type is intended for external consumption, and value-oriented data structures over pointer-heavy hierarchies. Avoid simulating object-oriented patterns (no inheritance, no sprawling interface trees that merely wrap structs). Compose behavior using plain functions and small structs grouped by responsibility—mirroring existing packages like `internal/service/collection` or `internal/api/rcollection`. Always pass `context.Context` as the first parameter and honor cancellation. For logging, reuse the project’s structured loggers rather than `fmt.Println`. Validate inputs early, return concrete error types (or wrap with `%w`) so that RPC layers can translate them into Connect status codes. Handle ULIDs, enumerations, and status flags using the helper modules already present (look at `packages/server/internal/idwrap`). When implementing concurrency, prefer channel-based coordination or `sync.WaitGroup` and avoid spawning goroutines without clear ownership. Keep functions under 50 lines when practical, extract helpers to private functions alongside the caller, and add doc comments (`// Package xyz ...`) on exported symbols.

## Performance & Benchmarking Discipline
Performance-sensitive paths—flow evaluation, RPC fan-out, database ingestion, worker execution—must be profiled before and after changes. Capture concrete evidence using the Go tooling stack: `go test ./packages/server/internal/service/... -run=^$ -bench=BenchmarkFlow -benchmem -cpuprofile=/tmp/flow.cpu` to gather CPU data, `-memprofile` for heap focus, and `go test ./... -trace=/tmp/server.trace` when latency spikes need tracing. Inspect these artifacts with `go tool pprof /tmp/flow.cpu` (use `top`, `list`, or `weblist`) or `go tool pprof -http=:0 /tmp/flow.cpu` for an interactive flame graph. Repeat runs (`-count=5`) and compare with `benchstat /tmp/before.txt /tmp/after.txt` to verify the improvement is statistically meaningful. When altering SQL, run benchmarks that stress the relevant services and augment them with SQLite insight: instrument queries with timers, capture `EXPLAIN QUERY PLAN` output, and validate that indexes in `packages/db` are actually hit. For heavily used RPCs, add targeted benchmarks in `*_test.go` files alongside the implementation (naming them `Benchmark<Name>`), and wire them into CI plans when feasible so future regressions surface quickly. Document profiling commands and outcomes in your final message so maintainers can reproduce your findings.

When optimizations require toggling behavior, create an A/B harness that exercises both the existing and proposed approach within the same benchmark, and report relative deltas. Keep the safer code path gated by a feature flag or `Experimental` config until the human maintainers green-light removal. Use realistic payloads captured from `packages/server/test` fixtures or from the flow recorder rather than synthetic data. For UI-focused performance, rely on the browser profiler plus React DevTools, but still express findings in reproducible steps (`pnpm nx run client:dev`, open DevTools, record interactions). Never trust intuition alone; every claim of “faster” must come with numbers.

## SQL & Data Access Patterns
Database access is orchestrated through sqlc-generated query packages located at `packages/server/pkg/gen`. Each query struct exposes methods that accept `context.Context` and typed parameters; call them directly or embed them in higher-level services. For single-component tests, use the pure-Go SQLite driver via `sqlitemem.NewSQLiteMem(ctx)` and close it with `t.Cleanup(cleanup)`. For multi-component scenarios, reach for `testutil.CreateBaseDB(ctx, t)` which wires up a shared in-memory SQLite DSN and exposes `BaseDBQueries`. Keep transactions short: start with `tx, err := db.BeginTx(ctx, nil)`, defer `devtoolsdb.TxnRollback(tx)`, perform writes, then explicitly commit before executing reads that run outside the transaction. SQL migrations and schema definitions live in the TypeSpec outputs; never edit generated SQL files manually. To seed data, rely on helpers such as `BaseTestServices.CreateTempCollection` or construct minimal insert statements in Go using sqlc types. Use parameterized queries, avoid dynamic SQL string concatenation, and store timestamps as `DATETIME` values in UTC. When you must add a query, update the sqlc configuration in `packages/server/sqlc.yaml`, regenerate with `pnpm nx run db:generate` (or the equivalent target), and document the intent in the PR description.

## Simplification & Composition Rules
Complexity is the enemy. Keep codepaths narrow by leaning on the existing service layers instead of duplicating logic. Prefer returning well-defined structs rather than `map[string]any`. If a handler starts to accumulate branching logic, extract pure functions into `internal/service` packages so they can be reused by multiple RPC endpoints. Always check for existing abstractions: the delta system already manages overridden entities, so new features should extend those types rather than invent parallel structures. When integrating SQL statements, reuse the query builders in `pkg/gen` rather than inlining raw SQL. Use feature flags sparingly and only when they fit the product roadmap described in `CLAUDE.md`. For configuration, respect the existing environment variable names and centralize new settings under the server config struct. Defer adding new dependencies unless the functionality cannot be achieved with the standard library or existing modules.

## TypeScript & UI Notes
Although Go may be the focus of your task, many features cross the boundary into TypeScript packages. TypeScript uses strict compiler settings, 2-space indentation, and single quotes. React code adheres to PascalCase for components, camelCase for hooks and functions, and co-located CSS (Tailwind 4). Effects and data fetching go through Effect-TS and TanStack Query; study the patterns in `packages/client/src/data` before introducing new ones. If you must edit TypeSpec files, run `pnpm nx run spec:build` afterward to regenerate protobuf and Connect clients, then check in only the source changes while leaving generated artifacts in `dist/`. Storybook lives under `packages/ui`; use `pnpm nx run ui:storybook` for component QA. Be mindful of accessibility expectations—leveraging React Aria components is preferred over bespoke keyboard handling.

## Testing Strategy
Testing spans multiple layers. For Go services, default to table-driven tests that call into sqlc-generated queries or service constructors. The testing guide at `packages/server/testing.md` outlines best practices: one in-memory database per test, short transactions, and deterministic seeds. Use `mwauth.CreateAuthedContext` when exercising RPC endpoints requiring authentication. For concurrency-sensitive code, rely on `context.WithTimeout` and avoid `time.Sleep`. UI and TypeScript packages should co-locate tests under the relevant directory and expose an Nx `test` target; integrate with Vitest or Jest consistent with existing packages. Execute `task test` for fast feedback and `task test:ci` when JSON reports are needed. If tests are flaky or long-running, document the trade-off in your final response and suggest mitigation steps. Never leave TODO comments in tests—write the missing coverage or capture the follow-up in the issue tracker instead.

## Commit, Review & Release Flow
Even though you will not commit by default, you must prepare changes as if a maintainer will review them immediately. Run `git status` and ensure only intentional files are touched. Provide diff summaries referencing `path:line`. Before the human author opens a PR, advise them to run `task lint` and `task test`, and to regenerate any derived artifacts touched by the change (`nx run spec:build`, `nx run db:generate`, Storybook snapshots, etc.). Remind them to attach screenshots for UI updates, note breaking changes, and generate an Nx Version Plan with `task version-plan --project=<scope>` or `nx release plan`. PR descriptions should include rationale, testing evidence, and linked issues. Encourage small, focused branches; if the change spans unrelated concerns, recommend splitting it into separate tasks.

### Commit Message Voice
- Start subject lines with an area tag or Conventional Commit type, optionally include scope parentheses, and keep the action in the imperative mood (e.g. `server(rnode): Ensure request IDs hydrate correctly`, `feat(cli): add modular flow reporters`).
- When no obvious type applies, stick with a short capitalized imperative phrase (`Fix flow run logs to use execution names`, `Export service: add curl text export path`).
- Separate additional detail with a blank line and use dash-prefixed bullets for follow-up points to match existing multi-line commit narratives.

## Security, Secrets & Compliance
Never check in secrets or personal data. Environment variables belong in `.env.development` (loaded via direnv) and must be mocked or stubbed in tests. Avoid adding dependencies that reach out to the network or write outside the workspace unless explicitly required. The repository ships under MIT + Commons Clause: reiterate this in documentation changes when relevant and ensure new code respects third-party license compatibility. When handling authentication flows, reuse existing middleware such as `mwauth` and avoid storing tokens in plaintext logs. Generated code destined for deployment (binaries, bundles) must stay out of the repository; use `dist/` or temporary directories and clean them up when you are done. If you discover sensitive data already committed, pause and escalate to the user.

## Pre-Delivery Checklist for Agents
Before you hand results back, walk through this checklist: (1) confirm the workspace is clean via `git status -sb`; (2) inspect `git diff` and ensure the narrative in your response aligns with the actual changes; (3) run relevant tests or state precisely why they were skipped; (4) verify formatting—Go files should pass `gofmt` and `pnpm nx run server:lint`, TypeScript should align with Prettier; (5) mention any manual follow-up steps the human developer should take (e.g., rebuild specs, update release plans); (6) highlight risks, edge cases, or assumptions left unresolved. Close with actionable next steps rather than generic sign-offs. This thoroughness keeps human collaborators confident that agent-authored contributions integrate smoothly with their workflow.
